{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.featuretools.com/\"><img src=\"img/featuretools-logo.png\" width=\"400\" height=\"200\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> New York City Taxi Ride Duration Prediction </h2>\n",
    "\n",
    "In this case study, we will build a predictive model to predict the duration of taxi ride. We will do the following steps:\n",
    "* First install the dependencies\n",
    "* Next load the data as pandas dataframe\n",
    "* Define the outcome variable- the variable we are trying to predict. \n",
    "* Build features using featuretools package - that implements Deep Feature Synthesis. We will start with simple features and incrementally improve the feature definitions and examine the accuracy of the system. \n",
    "\n",
    "Allocate atleast 2-3 hours to go through this case study end-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Install Dependencies</h2>\n",
    "<p>If you have not done so already, download this repository <a href=\"https://github.com/Featuretools/DSx/archive/master.zip\">from git</a>. Once you have downloaded this archive, unzip it and cd into the directory from the command line. Next run the command ``./install_osx.sh`` if you are on a mac or ``./install_linux.sh`` if you are on linux. This should install all of the dependencies.</p>\n",
    "<p> If you are on a windows machine, open the requirements.txt folder and make sure to install each of the dependencies listed (featuretools, jupyter, pandas, sklearn, xgboost, numpy) </p>\n",
    "<p> Once you have installed all of the dependencies, open this notebook. On Mac and Linux, navigate to the directory that you downloaded from git and run ``jupyter notebook`` to be taken to this notebook in your default web browser. When you open the NewYorkCity_taxi_case_study.ipynb file in the web browser, you can step through the code by clicking the ``Run`` button at the top of the page. If you have any questions for how to use Jupyter, refer to google or the discussion forum.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running the Code</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DAI-Lab-Github/NYC-Taxi-Demo/ft/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import featuretools as ft\n",
    "import utils\n",
    "from utils import load_nyc_taxi_data, compute_features\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from featuretools.primitives import (Day, Hour, Minute, Month, Weekday, Week, Weekend, Sum, Mean, Median, Std)\n",
    "ft.__version__\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download and load the raw data as pandas dataframes </h2>\n",
    "<p>If you have not yet downloaded the data it can be downloaded <a href=\"https://s3.amazonaws.com/mit-dsx-data/nyc-taxi-data.zip\">from S3</a>. Once you have downloaded the archive, unzip it and place trips.csv, passenger_cnt.csv, and vendors.csv in the nyc-taxi-data folder. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'dropoff_datetime' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b8d8c412c471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassenger_cnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvendors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_nyc_taxi_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DAI-Lab-Github/DSx/utils.pyc\u001b[0m in \u001b[0;36mload_nyc_taxi_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m                         \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pickup_datetime\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dropoff_datetime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'vendor_id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"category\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'passenger_count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                         encoding='utf-8')\n\u001b[0m\u001b[1;32m    151\u001b[0m     passenger_cnt = pd.read_csv('nyc-taxi-data/passenger_cnt.csv',\n\u001b[1;32m    152\u001b[0m                                 \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"first_trips_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DAI-Lab-Github/NYC-Taxi-Demo/ft/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DAI-Lab-Github/NYC-Taxi-Demo/ft/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DAI-Lab-Github/NYC-Taxi-Demo/ft/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DAI-Lab-Github/NYC-Taxi-Demo/ft/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DAI-Lab-Github/NYC-Taxi-Demo/ft/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1628\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Usecols do not match names.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_noconvert_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DAI-Lab-Github/NYC-Taxi-Demo/ft/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_set_noconvert_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1695\u001b[0m                         \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m                     \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/DAI-Lab-Github/NYC-Taxi-Demo/ft/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_set\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_noconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'dropoff_datetime' is not in list"
     ]
    }
   ],
   "source": [
    "trips, passenger_cnt, vendors = load_nyc_taxi_data()\n",
    "trips.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the Data \n",
    "Lets create entities and relationships. The three entities in this data are \n",
    "* trips \n",
    "* vendors (these are the cab companies)\n",
    "* passenger_cnt (a simple entity that has the unique number of passenger counts 1-8)\n",
    "\n",
    "This data has the following relationships\n",
    "* Vendors --> trips (the same vendor can have multiple trips - vendors is the ``parent_entity`` and trips it the child entity\n",
    "* passenger_cnt --> trips (the same passenger_cnt can appear in multiple trips. passenger_cnt is the ``parent_entity`` and trips is the child entity. \n",
    "\n",
    "In <a <href=\"https://www.featuretools.com/\"><featuretools (automated feature engineering software package)/></a>, we specify the list of entities and relationships as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = {\n",
    "        \"trips\": (trips, \"id\", 'pickup_datetime' ),\n",
    "        \"vendors\": (vendors, \"vendor_id\"),\n",
    "        \"passenger_cnt\": (passenger_cnt,\"passenger_count\")\n",
    "        }\n",
    "\n",
    "relationships = [(\"vendors\", \"vendor_id\",\"trips\", \"vendor_id\"), \n",
    "                (\"passenger_cnt\", \"passenger_count\",\"trips\", \"passenger_count\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We specify the time for each instance of the target_entity, in this case ``trips`` to calculate features. The timestamp represents the last time data can be used for calculating features by DFS. This is specified using a dataframe of cutoff time. This cutoff time for each trip is the pickup time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     pickup_datetime\n",
      "0   0 2016-01-01 00:00:19\n",
      "1   1 2016-01-01 00:01:45\n",
      "2   2 2016-01-01 00:01:47\n",
      "3   3 2016-01-01 00:01:48\n",
      "4   4 2016-01-01 00:02:49\n",
      "5   5 2016-01-01 00:03:21\n",
      "6   6 2016-01-01 00:04:20\n",
      "7   7 2016-01-01 00:05:06\n",
      "8   8 2016-01-01 00:05:06\n",
      "9   9 2016-01-01 00:05:15\n"
     ]
    }
   ],
   "source": [
    "cutoff_time = (trips[['id', 'pickup_datetime']])\n",
    "print cutoff_time.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3: Create baseline features using DFS </h2>\n",
    "<p>Instead of manually creating features, such as month of <b>pickup_datetime</b>, we can let featuretools come up with them. </p> \n",
    "\n",
    "Featuretools does this by \n",
    "* interpret the types of variables - categorical, numeric and others. We can override this interpretation by specifying the types. In this case study, we wanted <b>passenger_count</b> to be a type of Ordinal, and <b>vendor_id</b> to be of type Categorical. This override occured while loading in the csv files.</p>\n",
    "* then based on the primitives we specify, it matches up the columns to which those primitives can be applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create transform features using transform primitives\n",
    "\n",
    "As we described in the video, features fall into two major categories, ``transform`` and ``aggregate``. In featureools, we can create transform features by specifying ``transform`` primitives. Below we specify a ``transform`` primitive called ``weekend`` and here is what it does:\n",
    "\n",
    "* It can be applied to any ``datetime`` column in the data. \n",
    "* For each entry in the column, it assess if it is a ``weekend`` and returns a boolean. \n",
    "\n",
    "In this specific data, there are two ``datetime`` columns ``pickup_datetime`` and ``dropoff_datetime``. The tool automatically creates features using the primitive and these two columns as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_primitives = [Weekend]\n",
    "\n",
    "features = ft.dfs(entities=entities,\n",
    "                   relationships=relationships,\n",
    "                   target_entity=\"trips\",\n",
    "                   trans_primitives=trans_primitives,\n",
    "                   agg_primitives=[],\n",
    "                   features_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here are the features created.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Feature: vendor_id>,\n",
       " <Feature: passenger_count>,\n",
       " <Feature: payment_type>,\n",
       " <Feature: dropoff_longitude>,\n",
       " <Feature: pickup_latitude>,\n",
       " <Feature: trip_duration>,\n",
       " <Feature: store_and_fwd_flag>,\n",
       " <Feature: trip_distance>,\n",
       " <Feature: dropoff_latitude>,\n",
       " <Feature: pickup_longitude>,\n",
       " <Feature: IS_WEEKEND(dropoff_datetime)>,\n",
       " <Feature: IS_WEEKEND(pickup_datetime)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix = compute_features(features,cutoff_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 4: Build the Model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a model,\n",
    "* we first seperate the data into a porition for ``training`` (75% in this case) and a portion for ``testing`` \n",
    "* We also get the log of the trip duration so that a more linear relationship can be found.\n",
    "* We use ``XGBOOST`` to train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separates the whole feature matrix into train data feature matrix, train data labels, and test data feature matrix \n",
    "X_train, y_train, X_test, y_test = utils.get_train_test_fm(feature_matrix,.75)\n",
    "y_train = np.log(y_train.values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.98698\tvalid-rmse:4.98587\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.973206\tvalid-rmse:0.972554\n",
      "[20]\ttrain-rmse:0.436417\tvalid-rmse:0.436489\n",
      "[30]\ttrain-rmse:0.380745\tvalid-rmse:0.382061\n",
      "[40]\ttrain-rmse:0.37503\tvalid-rmse:0.377282\n",
      "[50]\ttrain-rmse:0.367368\tvalid-rmse:0.370566\n",
      "[60]\ttrain-rmse:0.362789\tvalid-rmse:0.366918\n",
      "[70]\ttrain-rmse:0.358907\tvalid-rmse:0.364013\n",
      "[80]\ttrain-rmse:0.357262\tvalid-rmse:0.362921\n",
      "[90]\ttrain-rmse:0.354699\tvalid-rmse:0.361165\n",
      "[100]\ttrain-rmse:0.353081\tvalid-rmse:0.360219\n",
      "[110]\ttrain-rmse:0.351461\tvalid-rmse:0.359141\n",
      "[120]\ttrain-rmse:0.35009\tvalid-rmse:0.358254\n",
      "[130]\ttrain-rmse:0.34822\tvalid-rmse:0.357092\n",
      "[140]\ttrain-rmse:0.346831\tvalid-rmse:0.35624\n",
      "[150]\ttrain-rmse:0.346074\tvalid-rmse:0.355775\n",
      "[160]\ttrain-rmse:0.345375\tvalid-rmse:0.3554\n",
      "[170]\ttrain-rmse:0.34477\tvalid-rmse:0.355074\n",
      "[180]\ttrain-rmse:0.343869\tvalid-rmse:0.35461\n",
      "[190]\ttrain-rmse:0.343394\tvalid-rmse:0.354408\n",
      "[200]\ttrain-rmse:0.343124\tvalid-rmse:0.354356\n",
      "[210]\ttrain-rmse:0.342747\tvalid-rmse:0.354204\n",
      "[220]\ttrain-rmse:0.342269\tvalid-rmse:0.353976\n",
      "[226]\ttrain-rmse:0.34179\tvalid-rmse:0.353823\n",
      "Modeling RMSE 0.35382\n"
     ]
    }
   ],
   "source": [
    "model = utils.train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 5: Adding more Transform Primitives</h2>\n",
    "\n",
    "* Adding ``Minute`` ``Hour`` ``Week`` ``Month`` ``Weekday`` primitives\n",
    "* All these transform primitives apply to ``datetime`` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_primitives = [Minute, Hour, Day, Week, Month, Weekday, Weekend]\n",
    "\n",
    "features = ft.dfs(entities=entities,\n",
    "                   relationships=relationships,\n",
    "                   target_entity=\"trips\",\n",
    "                   trans_primitives=trans_primitives,\n",
    "                   agg_primitives=[],\n",
    "                   features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Feature: passenger_count>,\n",
       " <Feature: dropoff_longitude>,\n",
       " <Feature: payment_type>,\n",
       " <Feature: store_and_fwd_flag>,\n",
       " <Feature: vendor_id>,\n",
       " <Feature: pickup_latitude>,\n",
       " <Feature: pickup_longitude>,\n",
       " <Feature: trip_duration>,\n",
       " <Feature: trip_distance>,\n",
       " <Feature: dropoff_latitude>,\n",
       " <Feature: WEEKDAY(pickup_datetime)>,\n",
       " <Feature: WEEK(dropoff_datetime)>,\n",
       " <Feature: HOUR(pickup_datetime)>,\n",
       " <Feature: WEEKDAY(dropoff_datetime)>,\n",
       " <Feature: DAY(pickup_datetime)>,\n",
       " <Feature: MONTH(pickup_datetime)>,\n",
       " <Feature: WEEK(pickup_datetime)>,\n",
       " <Feature: DAY(dropoff_datetime)>,\n",
       " <Feature: MONTH(dropoff_datetime)>,\n",
       " <Feature: HOUR(dropoff_datetime)>,\n",
       " <Feature: IS_WEEKEND(pickup_datetime)>,\n",
       " <Feature: IS_WEEKEND(dropoff_datetime)>,\n",
       " <Feature: MINUTE(pickup_datetime)>,\n",
       " <Feature: MINUTE(dropoff_datetime)>,\n",
       " <Feature: passenger_cnt.WEEK(first_trips_time)>,\n",
       " <Feature: vendors.DAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.WEEKDAY(first_trips_time)>,\n",
       " <Feature: vendors.WEEKDAY(first_trips_time)>,\n",
       " <Feature: vendors.MONTH(first_trips_time)>,\n",
       " <Feature: passenger_cnt.DAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.MINUTE(first_trips_time)>,\n",
       " <Feature: passenger_cnt.HOUR(first_trips_time)>,\n",
       " <Feature: vendors.HOUR(first_trips_time)>,\n",
       " <Feature: passenger_cnt.MONTH(first_trips_time)>,\n",
       " <Feature: vendors.MINUTE(first_trips_time)>,\n",
       " <Feature: vendors.WEEK(first_trips_time)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix = compute_features(features,cutoff_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 5: Build the new model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separates the whole feature matrix into train data feature matrix, train data labels, and test data feature matrix \n",
    "X_train, y_train, X_test, y_test = utils.get_train_test_fm(feature_matrix,.75)\n",
    "y_train = np.log(y_train.values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.99672\tvalid-rmse:4.99546\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:0.926123\tvalid-rmse:0.925607\n",
      "[20]\ttrain-rmse:0.398269\tvalid-rmse:0.398866\n",
      "[30]\ttrain-rmse:0.336353\tvalid-rmse:0.338614\n",
      "[40]\ttrain-rmse:0.319268\tvalid-rmse:0.322974\n",
      "[50]\ttrain-rmse:0.29361\tvalid-rmse:0.299003\n",
      "[60]\ttrain-rmse:0.281483\tvalid-rmse:0.288059\n",
      "[70]\ttrain-rmse:0.257367\tvalid-rmse:0.265217\n",
      "[80]\ttrain-rmse:0.242748\tvalid-rmse:0.251557\n",
      "[90]\ttrain-rmse:0.236299\tvalid-rmse:0.246339\n",
      "[100]\ttrain-rmse:0.221303\tvalid-rmse:0.232359\n",
      "[110]\ttrain-rmse:0.21447\tvalid-rmse:0.226336\n",
      "[120]\ttrain-rmse:0.205326\tvalid-rmse:0.217802\n",
      "[130]\ttrain-rmse:0.203326\tvalid-rmse:0.21675\n",
      "[140]\ttrain-rmse:0.195485\tvalid-rmse:0.209856\n",
      "[150]\ttrain-rmse:0.194128\tvalid-rmse:0.209188\n",
      "[160]\ttrain-rmse:0.187765\tvalid-rmse:0.203539\n",
      "[170]\ttrain-rmse:0.178377\tvalid-rmse:0.19481\n",
      "[180]\ttrain-rmse:0.175451\tvalid-rmse:0.19234\n",
      "[190]\ttrain-rmse:0.170608\tvalid-rmse:0.187837\n",
      "[200]\ttrain-rmse:0.168245\tvalid-rmse:0.185726\n",
      "[210]\ttrain-rmse:0.161733\tvalid-rmse:0.179729\n",
      "[220]\ttrain-rmse:0.160597\tvalid-rmse:0.179161\n",
      "[226]\ttrain-rmse:0.158871\tvalid-rmse:0.177684\n",
      "Modeling RMSE 0.17768\n"
     ]
    }
   ],
   "source": [
    "model = utils.train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 6: Add Aggregation Primitives</h2>\n",
    "\n",
    "Now let's add aggregation primitives. These primitives will generate features for the parent entities in this case both ``vendors`` and ``passenger_cnt`` and then add them to the trips entity (which is the entity for which we are trying to make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_primitives = [Minute, Hour, Day, Week, Month, Weekday, Weekend]\n",
    "aggregation_primitives = [Sum, Mean, Median, Std]\n",
    "\n",
    "features = ft.dfs(entities=entities,\n",
    "                   relationships=relationships,\n",
    "                   target_entity=\"trips\",\n",
    "                   trans_primitives=trans_primitives,\n",
    "                   agg_primitives=aggregation_primitives,\n",
    "                   drop_contains=['trips.test_data'],\n",
    "                   features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Feature: payment_type>,\n",
       " <Feature: store_and_fwd_flag>,\n",
       " <Feature: dropoff_longitude>,\n",
       " <Feature: pickup_longitude>,\n",
       " <Feature: trip_duration>,\n",
       " <Feature: vendor_id>,\n",
       " <Feature: passenger_count>,\n",
       " <Feature: pickup_latitude>,\n",
       " <Feature: trip_distance>,\n",
       " <Feature: dropoff_latitude>,\n",
       " <Feature: MONTH(pickup_datetime)>,\n",
       " <Feature: HOUR(dropoff_datetime)>,\n",
       " <Feature: MINUTE(pickup_datetime)>,\n",
       " <Feature: HOUR(pickup_datetime)>,\n",
       " <Feature: WEEKDAY(dropoff_datetime)>,\n",
       " <Feature: DAY(pickup_datetime)>,\n",
       " <Feature: IS_WEEKEND(pickup_datetime)>,\n",
       " <Feature: IS_WEEKEND(dropoff_datetime)>,\n",
       " <Feature: WEEK(dropoff_datetime)>,\n",
       " <Feature: WEEK(pickup_datetime)>,\n",
       " <Feature: MONTH(dropoff_datetime)>,\n",
       " <Feature: WEEKDAY(pickup_datetime)>,\n",
       " <Feature: DAY(dropoff_datetime)>,\n",
       " <Feature: MINUTE(dropoff_datetime)>,\n",
       " <Feature: passenger_cnt.STD(trips.pickup_longitude)>,\n",
       " <Feature: passenger_cnt.SUM(trips.pickup_longitude)>,\n",
       " <Feature: vendors.SUM(trips.dropoff_longitude)>,\n",
       " <Feature: passenger_cnt.WEEKDAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.STD(trips.payment_type)>,\n",
       " <Feature: vendors.MEDIAN(trips.trip_distance)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.trip_distance)>,\n",
       " <Feature: vendors.HOUR(first_trips_time)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.WEEKDAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.DAY(first_trips_time)>,\n",
       " <Feature: vendors.SUM(trips.pickup_longitude)>,\n",
       " <Feature: vendors.STD(trips.trip_distance)>,\n",
       " <Feature: passenger_cnt.SUM(trips.pickup_latitude)>,\n",
       " <Feature: passenger_cnt.STD(trips.trip_duration)>,\n",
       " <Feature: passenger_cnt.MINUTE(first_trips_time)>,\n",
       " <Feature: passenger_cnt.HOUR(first_trips_time)>,\n",
       " <Feature: passenger_cnt.SUM(trips.trip_duration)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.STD(trips.pickup_latitude)>,\n",
       " <Feature: vendors.STD(trips.trip_duration)>,\n",
       " <Feature: vendors.MEAN(trips.payment_type)>,\n",
       " <Feature: vendors.MEAN(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MONTH(first_trips_time)>,\n",
       " <Feature: vendors.SUM(trips.payment_type)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.payment_type)>,\n",
       " <Feature: vendors.MEDIAN(trips.dropoff_longitude)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.pickup_latitude)>,\n",
       " <Feature: passenger_cnt.MONTH(first_trips_time)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.dropoff_latitude)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.pickup_longitude)>,\n",
       " <Feature: vendors.WEEK(first_trips_time)>,\n",
       " <Feature: passenger_cnt.STD(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.STD(trips.payment_type)>,\n",
       " <Feature: passenger_cnt.WEEK(first_trips_time)>,\n",
       " <Feature: vendors.SUM(trips.trip_distance)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.trip_distance)>,\n",
       " <Feature: vendors.MEDIAN(trips.trip_duration)>,\n",
       " <Feature: vendors.STD(trips.dropoff_longitude)>,\n",
       " <Feature: vendors.DAY(first_trips_time)>,\n",
       " <Feature: passenger_cnt.STD(trips.pickup_latitude)>,\n",
       " <Feature: vendors.SUM(trips.pickup_latitude)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.trip_duration)>,\n",
       " <Feature: passenger_cnt.SUM(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MEDIAN(trips.pickup_latitude)>,\n",
       " <Feature: passenger_cnt.STD(trips.trip_distance)>,\n",
       " <Feature: vendors.SUM(trips.trip_duration)>,\n",
       " <Feature: passenger_cnt.SUM(trips.dropoff_longitude)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.pickup_latitude)>,\n",
       " <Feature: vendors.STD(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.SUM(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MEAN(trips.pickup_latitude)>,\n",
       " <Feature: vendors.MINUTE(first_trips_time)>,\n",
       " <Feature: passenger_cnt.SUM(trips.payment_type)>,\n",
       " <Feature: vendors.MEAN(trips.trip_distance)>,\n",
       " <Feature: vendors.MEAN(trips.trip_duration)>,\n",
       " <Feature: vendors.STD(trips.pickup_longitude)>,\n",
       " <Feature: vendors.MEDIAN(trips.pickup_longitude)>,\n",
       " <Feature: passenger_cnt.MEAN(trips.pickup_longitude)>,\n",
       " <Feature: vendors.MEDIAN(trips.dropoff_latitude)>,\n",
       " <Feature: passenger_cnt.SUM(trips.trip_distance)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.payment_type)>,\n",
       " <Feature: passenger_cnt.STD(trips.dropoff_latitude)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.trip_duration)>,\n",
       " <Feature: vendors.MEDIAN(trips.payment_type)>,\n",
       " <Feature: passenger_cnt.MEDIAN(trips.dropoff_latitude)>,\n",
       " <Feature: vendors.MEAN(trips.pickup_longitude)>,\n",
       " <Feature: vendors.MEAN(trips.dropoff_longitude)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix = compute_features(features,cutoff_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 6: Build the new model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separates the whole feature matrix into train data feature matrix, train data labels, and test data feature matrix \n",
    "X_train, y_train, X_test, y_test = utils.get_train_test_fm(feature_matrix,.75)\n",
    "y_train = np.log(y_train.values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3d5e2599dd3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/rkelly/DSx/utils.pyc\u001b[0m in \u001b[0;36mtrain_xgb\u001b[0;34m(X_train, labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     Xtr, Xv, ytr, yv = train_test_split(X_train.values,\n\u001b[0m\u001b[1;32m     35\u001b[0m                                         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mflot64\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m         \"\"\"\n\u001b[0;32m-> 3161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m   3140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m   3448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3450\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3475\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3476\u001b[0m             \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3477\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3478\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = utils.train_xgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 7: Evalute on test data  </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = utils.predict_xgb(model, X_test)\n",
    "y_pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred['trip_duration'])**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Additional Analysis</h2>\n",
    "<p>Let's look at how important each feature was for the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.values\n",
    "ft_importances = utils.feature_importances(model, feature_names)\n",
    "ft_importances[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft",
   "language": "python",
   "name": "ft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
